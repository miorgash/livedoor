{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f0de66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEVICE': 'cuda',\n",
      " 'DIR_BIN': '/tmp/work/livedoor/bin',\n",
      " 'DIR_DATA': '/tmp/work/livedoor/data',\n",
      " 'DIR_LOG': '/tmp/work/livedoor/log',\n",
      " 'DIR_MECAB_DIC': '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd',\n",
      " 'DIR_MODEL': '/tmp/work/livedoor/model',\n",
      " 'ROOT': '/tmp/work/livedoor',\n",
      " 'SAMPLE_SENT': 'ワンマンライブに行きたい。',\n",
      " 'SEED': 123,\n",
      " 'TOKENIZER': 'mecab'}\n"
     ]
    }
   ],
   "source": [
    "# primitive\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# text\n",
    "import MeCab\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "# **\n",
    "# handmade libs\n",
    "# *\n",
    "src = '../../src'\n",
    "if src not in sys.path: sys.path.append(src)\n",
    "\n",
    "# constants\n",
    "from const import *\n",
    "constants = {k: v for k, v in locals().items() if k.isupper()}\n",
    "pprint(constants)\n",
    "\n",
    "# modules\n",
    "from my_tokenizer import get_tokenizer\n",
    "from livedoor_dataset import LivedoorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd3178",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca571d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7366, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>前回の「プロに聞く“合コンの極意”（前編）　合コンアナリスト水谷麻衣に聞く、合コンの勝ちパタ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>「3年で転職は早すぎる？」「将来が見えない」「仕事が面白くない」・・・若手社会人の悩みは尽き...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>こんにちは、「ビズリーチ年収1000万円研究所」所長の佐藤和男です。この研究所では、年収10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6月7日、表参道のカフェバー「MERCER CAFE TERRACE HOUSE」でHenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>「3年で転職は早すぎる？」「将来が見えない」「仕事が面白くない」・・・若手社会人の悩みは尽き...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   media                                               text\n",
       "0      3  前回の「プロに聞く“合コンの極意”（前編）　合コンアナリスト水谷麻衣に聞く、合コンの勝ちパタ...\n",
       "1      3  「3年で転職は早すぎる？」「将来が見えない」「仕事が面白くない」・・・若手社会人の悩みは尽き...\n",
       "2      3  こんにちは、「ビズリーチ年収1000万円研究所」所長の佐藤和男です。この研究所では、年収10...\n",
       "3      3  6月7日、表参道のカフェバー「MERCER CAFE TERRACE HOUSE」でHenn...\n",
       "4      3  「3年で転職は早すぎる？」「将来が見えない」「仕事が面白くない」・・・若手社会人の悩みは尽き..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_afcf7_row0_col0,#T_afcf7_row0_col1,#T_afcf7_row0_col4,#T_afcf7_row0_col8{\n",
       "            background-color:  #084488;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_afcf7_row0_col2{\n",
       "            background-color:  #084990;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_afcf7_row0_col3{\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }#T_afcf7_row0_col5{\n",
       "            background-color:  #0d57a1;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_afcf7_row0_col6{\n",
       "            background-color:  #3787c0;\n",
       "            color:  #000000;\n",
       "        }#T_afcf7_row0_col7{\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_afcf7_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>        <th class=\"col_heading level0 col7\" >7</th>        <th class=\"col_heading level0 col8\" >8</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_afcf7_level0_row0\" class=\"row_heading level0 row0\" >media</th>\n",
       "                        <td id=\"T_afcf7_row0_col0\" class=\"data row0 col0\" >870</td>\n",
       "                        <td id=\"T_afcf7_row0_col1\" class=\"data row0 col1\" >870</td>\n",
       "                        <td id=\"T_afcf7_row0_col2\" class=\"data row0 col2\" >863</td>\n",
       "                        <td id=\"T_afcf7_row0_col3\" class=\"data row0 col3\" >511</td>\n",
       "                        <td id=\"T_afcf7_row0_col4\" class=\"data row0 col4\" >870</td>\n",
       "                        <td id=\"T_afcf7_row0_col5\" class=\"data row0 col5\" >842</td>\n",
       "                        <td id=\"T_afcf7_row0_col6\" class=\"data row0 col6\" >770</td>\n",
       "                        <td id=\"T_afcf7_row0_col7\" class=\"data row0 col7\" >900</td>\n",
       "                        <td id=\"T_afcf7_row0_col8\" class=\"data row0 col8\" >870</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe648af7590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ld_df = pd.read_csv(os.path.join(DIR_DATA, 'livedoor&text=text.csv'))\n",
    "\n",
    "# 概観\n",
    "print(ld_df.shape)\n",
    "display(ld_df.head())\n",
    "display(pd.DataFrame(ld_df.media.value_counts()).sort_index().T.style.background_gradient('Blues', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6acbc03",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6855feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_e13dd_row0_col0{\n",
       "            background-color:  #084a91;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_e13dd_row0_col1,#T_e13dd_row0_col5{\n",
       "            background-color:  #09529d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_e13dd_row0_col2{\n",
       "            background-color:  #08509b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_e13dd_row0_col3{\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }#T_e13dd_row0_col4{\n",
       "            background-color:  #105ba4;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_e13dd_row0_col6{\n",
       "            background-color:  #2d7dbb;\n",
       "            color:  #000000;\n",
       "        }#T_e13dd_row0_col7{\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_e13dd_row0_col8{\n",
       "            background-color:  #084990;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_e13dd_\" ><thead>    <tr>        <th class=\"index_name level0\" >0</th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>        <th class=\"col_heading level0 col7\" >7</th>        <th class=\"col_heading level0 col8\" >8</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e13dd_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_e13dd_row0_col0\" class=\"data row0 col0\" >698</td>\n",
       "                        <td id=\"T_e13dd_row0_col1\" class=\"data row0 col1\" >687</td>\n",
       "                        <td id=\"T_e13dd_row0_col2\" class=\"data row0 col2\" >690</td>\n",
       "                        <td id=\"T_e13dd_row0_col3\" class=\"data row0 col3\" >392</td>\n",
       "                        <td id=\"T_e13dd_row0_col4\" class=\"data row0 col4\" >675</td>\n",
       "                        <td id=\"T_e13dd_row0_col5\" class=\"data row0 col5\" >688</td>\n",
       "                        <td id=\"T_e13dd_row0_col6\" class=\"data row0 col6\" >632</td>\n",
       "                        <td id=\"T_e13dd_row0_col7\" class=\"data row0 col7\" >732</td>\n",
       "                        <td id=\"T_e13dd_row0_col8\" class=\"data row0 col8\" >699</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe5b7873110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_8f824_row0_col0{\n",
       "            background-color:  #2f7fbc;\n",
       "            color:  #000000;\n",
       "        }#T_8f824_row0_col1{\n",
       "            background-color:  #0e59a2;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_8f824_row0_col2{\n",
       "            background-color:  #2c7cba;\n",
       "            color:  #000000;\n",
       "        }#T_8f824_row0_col3{\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }#T_8f824_row0_col4{\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_8f824_row0_col5{\n",
       "            background-color:  #7cb7da;\n",
       "            color:  #000000;\n",
       "        }#T_8f824_row0_col6{\n",
       "            background-color:  #c6dbef;\n",
       "            color:  #000000;\n",
       "        }#T_8f824_row0_col7{\n",
       "            background-color:  #3c8cc3;\n",
       "            color:  #000000;\n",
       "        }#T_8f824_row0_col8{\n",
       "            background-color:  #3282be;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_8f824_\" ><thead>    <tr>        <th class=\"index_name level0\" >0</th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>        <th class=\"col_heading level0 col7\" >7</th>        <th class=\"col_heading level0 col8\" >8</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_8f824_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_8f824_row0_col0\" class=\"data row0 col0\" >172</td>\n",
       "                        <td id=\"T_8f824_row0_col1\" class=\"data row0 col1\" >183</td>\n",
       "                        <td id=\"T_8f824_row0_col2\" class=\"data row0 col2\" >173</td>\n",
       "                        <td id=\"T_8f824_row0_col3\" class=\"data row0 col3\" >119</td>\n",
       "                        <td id=\"T_8f824_row0_col4\" class=\"data row0 col4\" >195</td>\n",
       "                        <td id=\"T_8f824_row0_col5\" class=\"data row0 col5\" >154</td>\n",
       "                        <td id=\"T_8f824_row0_col6\" class=\"data row0 col6\" >138</td>\n",
       "                        <td id=\"T_8f824_row0_col7\" class=\"data row0 col7\" >168</td>\n",
       "                        <td id=\"T_8f824_row0_col8\" class=\"data row0 col8\" >171</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe64c565150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get torch dataset\n",
    "dataset = LivedoorDataset(ld_df)\n",
    "\n",
    "# split dataset\n",
    "TEST_RATE = 0.20\n",
    "n = len(dataset)\n",
    "n_test = int(np.floor(n * TEST_RATE))\n",
    "n_train = int(n - n_test)\n",
    "train_dataset, test_dataset = \\\n",
    "        random_split(dataset, [n_train, n_test], generator=torch.Generator().manual_seed(12345))\n",
    "\n",
    "def show_dataset_label_balance(dataset):\n",
    "    c = Counter([l for l, _ in dataset])\n",
    "    df = pd.DataFrame(c.most_common()).set_index(0).sort_index().T\n",
    "    display(df.style.background_gradient('Blues', axis=1))\n",
    "\n",
    "show_dataset_label_balance(train_dataset)\n",
    "show_dataset_label_balance(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681178e5",
   "metadata": {},
   "source": [
    "Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e98e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : ['ワンマンライブ', 'に', '行き', 'たい', '。']\n"
     ]
    }
   ],
   "source": [
    "# Construct vocabulary; using only train and valid dataset\n",
    "tokenizer = get_tokenizer('mecab')\n",
    "print('output :', tokenizer(SAMPLE_SENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809a86f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 1000 samples done |  1.08 s |\n",
      "| 2000 samples done |  1.10 s |\n",
      "| 3000 samples done |  1.08 s |\n",
      "| 4000 samples done |  1.07 s |\n",
      "| 5000 samples done |  1.08 s |\n",
      "/tmp/work/livedoor/bin/vocab_mecab.pkl : file exists\n",
      "[38795, 5, 1283, 66, 4]\n",
      "CPU times: user 6.61 s, sys: 48.5 ms, total: 6.66 s\n",
      "Wall time: 6.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = Counter()\n",
    "# logging\n",
    "start = time()\n",
    "\n",
    "for e, (label, text) in enumerate(train_dataset):\n",
    "    counter.update(tokenizer(text))\n",
    "    \n",
    "    # logging\n",
    "    if e!=0 and e%(1000)==0:\n",
    "        current = time()\n",
    "        interval = current-start\n",
    "        print(f'| {(e):4d} samples done | {interval:5.2f} s |')\n",
    "        start = current\n",
    "        \n",
    "vocab = Vocab(counter, min_freq=1)\n",
    "PAD = vocab.stoi['<pad>']\n",
    "\n",
    "# serialize\n",
    "file_out = os.path.join(DIR_BIN, f'vocab_{TOKENIZER}.pkl') # 本当は dic で分けるべき\n",
    "if not os.path.isfile(file_out):\n",
    "    with open(file_out, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    print(f'{file_out} : created')\n",
    "else:\n",
    "    print(f'{file_out} : file exists')\n",
    "\n",
    "# test; \n",
    "print([vocab[str(token)] for token in tokenizer(SAMPLE_SENT)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b3a3c",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a3f62",
   "metadata": {},
   "source": [
    "Class, Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7e731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RandomEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(RandomEmbedding, self).__init__()\n",
    "        torch.manual_seed(SEED)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "    \n",
    "    def forward(self, texts):\n",
    "        return self.embedding(texts)\n",
    "\n",
    "random_emb = RandomEmbedding(len(vocab), 10)\n",
    "emb = random_emb(torch.tensor([[2, 3, 4, 5, 6],\n",
    "                               [2, 3, 4, 1, 1]])).detach().numpy()[1]\n",
    "sns.heatmap(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915d46f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim, h_dim, class_dim):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        torch.manual_seed(SEED)\n",
    "        self.embedding = RandomEmbedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, h_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(h_dim, class_dim)\n",
    "        \n",
    "#         # init weight\n",
    "#         self.embedding.\n",
    "        \n",
    "    def forward(self, texts):\n",
    "        emb = self.embedding(texts)\n",
    "        o, (h_n, c_n) = self.lstm(emb)\n",
    "        out = self.linear(h_n)\n",
    "        return out\n",
    "\n",
    "# test\n",
    "lstm = LSTMClassifier(len(vocab), 300, 100, 9)\n",
    "input_ = torch.tensor(np.random.randint(0, 90000, [3, 300]))\n",
    "output = lstm(input_).detach().squeeze().numpy()\n",
    "sns.heatmap(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d741c254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim, h_dim, class_dim):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        torch.manual_seed(SEED)\n",
    "        self.embedding = RandomEmbedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, h_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(h_dim, class_dim)\n",
    "        \n",
    "#         # init weight\n",
    "#         self.embedding.\n",
    "        \n",
    "    def forward(self, texts):\n",
    "        emb = self.embedding(texts)\n",
    "        o, (h_n, c_n) = self.lstm(emb)\n",
    "        out = self.linear(h_n)\n",
    "        return out\n",
    "\n",
    "# test\n",
    "lstm = LSTMClassifier(len(vocab), 300, 100, 9)\n",
    "input_ = torch.tensor(np.random.randint(0, 90000, [3, 300]))\n",
    "output = lstm(input_).detach().squeeze().numpy()\n",
    "sns.heatmap(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3dd0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_4c949_row0_col0{\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_4c949_row1_col0{\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_4c949_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >1</th>    </tr>    <tr>        <th class=\"index_name level0\" >0</th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4c949_level0_row0\" class=\"row_heading level0 row0\" >5</th>\n",
       "                        <td id=\"T_4c949_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4c949_level0_row1\" class=\"row_heading level0 row1\" >6</th>\n",
       "                        <td id=\"T_4c949_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe5b2ec6290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(output.argmax(axis=1)).most_common()\n",
    "pd.DataFrame(freq).set_index(0).style.background_gradient('Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5211e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer, label\n",
    "text_pipeline = lambda text: [vocab.stoi[str(token)] for token in tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfa5f28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | batch  30 | correct total: 0.11995968 | loss total: 0.03439050 |\n",
      "|       | batch  60 | correct total: 0.11936475 | loss total: 0.03437985 |\n",
      "|       | batch  90 | correct total: 0.11761676 | loss total: 0.03439184 |\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "def iter_train(dataloader, model, loss_fn, optimizer):\n",
    "    current_size = 0\n",
    "    current_loss, current_correct = 0, 0\n",
    "    \n",
    "    for batch, (labels, texts) in enumerate(dataloader):\n",
    "        \n",
    "        # indexing\n",
    "        texts = [torch.tensor(text_pipeline(text)) for text in texts]\n",
    "        texts = pad_sequence(texts, batch_first=True, padding_value=PAD)\n",
    "            \n",
    "        # send to GPU\n",
    "        labels, texts = labels.to(DEVICE), texts.to(DEVICE)\n",
    "\n",
    "        # pred\n",
    "        pred = model(texts)[0]\n",
    "\n",
    "        # get loss\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        # get gradient\n",
    "        optimizer.zero_grad() # バッチごとに勾配をリセット\n",
    "        loss.backward()\n",
    "\n",
    "        # back propagate\n",
    "        # 手動；todo: optimizer.step() の動作確認，デバッグ\n",
    "        for layer_num, param in enumerate(model.parameters()):\n",
    "            if layer_num==0:\n",
    "                continue\n",
    "            LR = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            param.data -= LR * param.grad.data\n",
    "#         optimizer.step()\n",
    "        \n",
    "        current_size += len(labels)\n",
    "        current_loss += loss.item()\n",
    "        current_correct += (pred.argmax(axis=1).squeeze()==labels).type(torch.int).sum().item()\n",
    "        \n",
    "        mean_loss = current_loss/current_size\n",
    "        mean_correct = current_correct/current_size\n",
    "\n",
    "        # logging\n",
    "        if batch%30==0 and batch!=0:\n",
    "            split = 'train'\n",
    "            print(f'| {split*(1 if batch==0 else 0):5} | batch {batch:3d} '\n",
    "                  f'| correct total: {mean_correct:0.8f} | loss total: {mean_loss:0.8f} |')\n",
    "    \n",
    "    return mean_correct, mean_loss\n",
    "\n",
    "if DEVICE=='cuda':\n",
    "    # 1 epoch sample execution\n",
    "    sample_dataloader = DataLoader(train_dataset,\n",
    "                                   batch_size=64,\n",
    "                                   shuffle=False,)\n",
    "    LR = 1e-4\n",
    "    model = LSTMClassifier(len(vocab), 300, 100, 9).to(DEVICE)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "    iter_train(sample_dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbeca285",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test  | accuracy: 0.1032 | loss avg: 0.03583317 |"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "def iter_test(dataloader, model, loss_fn):\n",
    "    test_size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 全ての勾配計算を無効化\n",
    "        for batch, (labels, texts) in enumerate(dataloader):\n",
    "            \n",
    "            # indexing\n",
    "            texts = [torch.tensor(text_pipeline(text)) for text in texts]\n",
    "            texts = pad_sequence(texts, batch_first=True, padding_value=PAD)\n",
    "            \n",
    "            # send to GPU\n",
    "            labels, texts = labels.to(DEVICE), texts.to(DEVICE)\n",
    "            \n",
    "            # predict\n",
    "            pred = model(texts)[0]\n",
    "\n",
    "            # get loss\n",
    "            test_loss += loss_fn(pred, labels).item()\n",
    "\n",
    "            # eval\n",
    "            pred_labels = pred.argmax(axis=1).squeeze() # この squeeze は問題ないのか？\n",
    "            correct += (pred_labels==labels).type(torch.int).sum().item()\n",
    "\n",
    "    correct /= test_size # Epoch 終了時点の Accuracy（正答数 / テストサンプルサイズ）\n",
    "    test_loss /= test_size # Epoch 終了時点の 1 サンプルあたり Loss 平均（Loss / テストサンプルサイズ）\n",
    "\n",
    "    split = 'test'\n",
    "    print(f'| {split:5} | accuracy: {correct:0.4f} | loss avg: {test_loss:6.8f} |', end='')\n",
    "    \n",
    "    return correct, test_loss\n",
    "\n",
    "if DEVICE=='cuda':\n",
    "    # sample execution\n",
    "    sample_dataloader = DataLoader(test_dataset,\n",
    "                                   batch_size=64,\n",
    "                                   shuffle=False,)\n",
    "    LR = 1e-2\n",
    "    model = LSTMClassifier(len(vocab), 300, 100, 9).to(DEVICE)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "    iter_test(sample_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcf8da",
   "metadata": {},
   "source": [
    "Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c856810c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Epoch 0 ----------------------------\n",
      "|       | batch  30 | correct total: 0.09979839 | loss total: 0.06870372 |\n",
      "|       | batch  60 | correct total: 0.10604508 | loss total: 0.06860261 |\n",
      "|       | batch  90 | correct total: 0.10405220 | loss total: 0.06854581 |\n",
      "|       | batch 120 | correct total: 0.10847107 | loss total: 0.06850113 |\n",
      "|       | batch 150 | correct total: 0.11196192 | loss total: 0.06844615 |\n",
      "|       | batch 180 | correct total: 0.11861188 | loss total: 0.06836882 |\n",
      "| test  | accuracy: 0.1195 | loss avg: 0.06977707 | 51.59 sec |\n",
      "---------------------------- Epoch 1 ----------------------------\n",
      "|       | batch  30 | correct total: 0.11693548 | loss total: 0.06842511 |\n",
      "|       | batch  60 | correct total: 0.13217213 | loss total: 0.06823190 |\n",
      "|       | batch  90 | correct total: 0.12568681 | loss total: 0.06813983 |\n",
      "|       | batch 120 | correct total: 0.13248967 | loss total: 0.06812349 |\n",
      "|       | batch 150 | correct total: 0.13327815 | loss total: 0.06812066 |\n",
      "|       | batch 180 | correct total: 0.13259669 | loss total: 0.06817159 |\n",
      "| test  | accuracy: 0.1242 | loss avg: 0.06972815 | 102.73 sec |\n",
      "---------------------------- Epoch 2 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13508065 | loss total: 0.06816220 |\n",
      "|       | batch  60 | correct total: 0.13063525 | loss total: 0.06809447 |\n",
      "|       | batch  90 | correct total: 0.12637363 | loss total: 0.06806280 |\n",
      "|       | batch 120 | correct total: 0.13094008 | loss total: 0.06805111 |\n",
      "|       | batch 150 | correct total: 0.12996689 | loss total: 0.06803954 |\n",
      "|       | batch 180 | correct total: 0.13225138 | loss total: 0.06802604 |\n",
      "| test  | accuracy: 0.1270 | loss avg: 0.06967855 | 154.16 sec |\n",
      "---------------------------- Epoch 3 ----------------------------\n",
      "|       | batch  30 | correct total: 0.12500000 | loss total: 0.06815660 |\n",
      "|       | batch  60 | correct total: 0.13370902 | loss total: 0.06812672 |\n",
      "|       | batch  90 | correct total: 0.12431319 | loss total: 0.06808618 |\n",
      "|       | batch 120 | correct total: 0.12525826 | loss total: 0.06805025 |\n",
      "|       | batch 150 | correct total: 0.12479305 | loss total: 0.06795612 |\n",
      "|       | batch 180 | correct total: 0.12672652 | loss total: 0.06794985 |\n",
      "| test  | accuracy: 0.1297 | loss avg: 0.06971907 | 205.58 sec |\n",
      "---------------------------- Epoch 4 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15221774 | loss total: 0.06781839 |\n",
      "|       | batch  60 | correct total: 0.14139344 | loss total: 0.06787909 |\n",
      "|       | batch  90 | correct total: 0.14320055 | loss total: 0.06789745 |\n",
      "|       | batch 120 | correct total: 0.13920455 | loss total: 0.06794023 |\n",
      "|       | batch 150 | correct total: 0.13721026 | loss total: 0.06790896 |\n",
      "|       | batch 180 | correct total: 0.13950276 | loss total: 0.06781861 |\n",
      "| test  | accuracy: 0.1310 | loss avg: 0.06944164 | 256.64 sec |\n",
      "---------------------------- Epoch 5 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13306452 | loss total: 0.06783425 |\n",
      "|       | batch  60 | correct total: 0.13012295 | loss total: 0.06778257 |\n",
      "|       | batch  90 | correct total: 0.13255495 | loss total: 0.06772841 |\n",
      "|       | batch 120 | correct total: 0.13145661 | loss total: 0.06765934 |\n",
      "|       | batch 150 | correct total: 0.13245033 | loss total: 0.06766685 |\n",
      "|       | batch 180 | correct total: 0.13518646 | loss total: 0.06767590 |\n",
      "| test  | accuracy: 0.1276 | loss avg: 0.06970564 | 308.37 sec |\n",
      "---------------------------- Epoch 6 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15120968 | loss total: 0.06761268 |\n",
      "|       | batch  60 | correct total: 0.14805328 | loss total: 0.06748101 |\n",
      "|       | batch  90 | correct total: 0.13907967 | loss total: 0.06761154 |\n",
      "|       | batch 120 | correct total: 0.13894628 | loss total: 0.06765430 |\n",
      "|       | batch 150 | correct total: 0.14176325 | loss total: 0.06759680 |\n",
      "|       | batch 180 | correct total: 0.14209254 | loss total: 0.06760011 |\n",
      "| test  | accuracy: 0.1263 | loss avg: 0.06959155 | 359.31 sec |\n",
      "---------------------------- Epoch 7 ----------------------------\n",
      "|       | batch  30 | correct total: 0.10887097 | loss total: 0.06756033 |\n",
      "|       | batch  60 | correct total: 0.11782787 | loss total: 0.06766183 |\n",
      "|       | batch  90 | correct total: 0.12122253 | loss total: 0.06763566 |\n",
      "|       | batch 120 | correct total: 0.12474174 | loss total: 0.06763246 |\n",
      "|       | batch 150 | correct total: 0.12748344 | loss total: 0.06756010 |\n",
      "|       | batch 180 | correct total: 0.13104282 | loss total: 0.06753032 |\n",
      "| test  | accuracy: 0.1358 | loss avg: 0.06850803 | 410.33 sec |\n",
      "---------------------------- Epoch 8 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14516129 | loss total: 0.06751901 |\n",
      "|       | batch  60 | correct total: 0.14190574 | loss total: 0.06739864 |\n",
      "|       | batch  90 | correct total: 0.13530220 | loss total: 0.06749236 |\n",
      "|       | batch 120 | correct total: 0.14127066 | loss total: 0.06751350 |\n",
      "|       | batch 150 | correct total: 0.14010762 | loss total: 0.06752519 |\n",
      "|       | batch 180 | correct total: 0.14036602 | loss total: 0.06753012 |\n",
      "| test  | accuracy: 0.1337 | loss avg: 0.06964783 | 461.12 sec |\n",
      "---------------------------- Epoch 9 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13004032 | loss total: 0.06724726 |\n",
      "|       | batch  60 | correct total: 0.13780738 | loss total: 0.06726633 |\n",
      "|       | batch  90 | correct total: 0.13839286 | loss total: 0.06737765 |\n",
      "|       | batch 120 | correct total: 0.14075413 | loss total: 0.06743681 |\n",
      "|       | batch 150 | correct total: 0.14279801 | loss total: 0.06734849 |\n",
      "|       | batch 180 | correct total: 0.14071133 | loss total: 0.06732394 |\n",
      "| test  | accuracy: 0.1208 | loss avg: 0.06840627 | 512.20 sec |\n",
      "---------------------------- Epoch 10 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15020161 | loss total: 0.06721418 |\n",
      "|       | batch  60 | correct total: 0.15163934 | loss total: 0.06744569 |\n",
      "|       | batch  90 | correct total: 0.14869505 | loss total: 0.06739765 |\n",
      "|       | batch 120 | correct total: 0.14824380 | loss total: 0.06734851 |\n",
      "|       | batch 150 | correct total: 0.14466060 | loss total: 0.06731749 |\n",
      "|       | batch 180 | correct total: 0.14399171 | loss total: 0.06735090 |\n",
      "| test  | accuracy: 0.1399 | loss avg: 0.06799485 | 563.56 sec |\n",
      "---------------------------- Epoch 11 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13306452 | loss total: 0.06757011 |\n",
      "|       | batch  60 | correct total: 0.14651639 | loss total: 0.06731595 |\n",
      "|       | batch  90 | correct total: 0.14285714 | loss total: 0.06731570 |\n",
      "|       | batch 120 | correct total: 0.14333678 | loss total: 0.06718308 |\n",
      "|       | batch 150 | correct total: 0.14031457 | loss total: 0.06723360 |\n",
      "|       | batch 180 | correct total: 0.13933011 | loss total: 0.06727597 |\n",
      "| test  | accuracy: 0.1283 | loss avg: 0.06772710 | 614.89 sec |\n",
      "---------------------------- Epoch 12 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13608871 | loss total: 0.06676772 |\n",
      "|       | batch  60 | correct total: 0.13883197 | loss total: 0.06703445 |\n",
      "|       | batch  90 | correct total: 0.14114011 | loss total: 0.06703617 |\n",
      "|       | batch 120 | correct total: 0.14023760 | loss total: 0.06712697 |\n",
      "|       | batch 150 | correct total: 0.14052152 | loss total: 0.06714361 |\n",
      "|       | batch 180 | correct total: 0.13967541 | loss total: 0.06722398 |\n",
      "| test  | accuracy: 0.1270 | loss avg: 0.07013722 | 666.21 sec |\n",
      "---------------------------- Epoch 13 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15826613 | loss total: 0.06724568 |\n",
      "|       | batch  60 | correct total: 0.15317623 | loss total: 0.06727531 |\n",
      "|       | batch  90 | correct total: 0.15281593 | loss total: 0.06728309 |\n",
      "|       | batch 120 | correct total: 0.14695248 | loss total: 0.06725208 |\n",
      "|       | batch 150 | correct total: 0.14486755 | loss total: 0.06724966 |\n",
      "|       | batch 180 | correct total: 0.14520028 | loss total: 0.06721563 |\n",
      "| test  | accuracy: 0.1310 | loss avg: 0.06771873 | 717.05 sec |\n",
      "---------------------------- Epoch 14 ----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | batch  30 | correct total: 0.13104839 | loss total: 0.06713116 |\n",
      "|       | batch  60 | correct total: 0.14036885 | loss total: 0.06710721 |\n",
      "|       | batch  90 | correct total: 0.13427198 | loss total: 0.06706669 |\n",
      "|       | batch 120 | correct total: 0.13842975 | loss total: 0.06714698 |\n",
      "|       | batch 150 | correct total: 0.13907285 | loss total: 0.06712833 |\n",
      "|       | batch 180 | correct total: 0.13777624 | loss total: 0.06711923 |\n",
      "| test  | accuracy: 0.1317 | loss avg: 0.06823461 | 767.89 sec |\n",
      "---------------------------- Epoch 15 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15725806 | loss total: 0.06739320 |\n",
      "|       | batch  60 | correct total: 0.14190574 | loss total: 0.06732751 |\n",
      "|       | batch  90 | correct total: 0.13873626 | loss total: 0.06730462 |\n",
      "|       | batch 120 | correct total: 0.14049587 | loss total: 0.06715057 |\n",
      "|       | batch 150 | correct total: 0.13907285 | loss total: 0.06712671 |\n",
      "|       | batch 180 | correct total: 0.14140193 | loss total: 0.06712258 |\n",
      "| test  | accuracy: 0.1337 | loss avg: 0.07037945 | 818.66 sec |\n",
      "---------------------------- Epoch 16 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13911290 | loss total: 0.06691756 |\n",
      "|       | batch  60 | correct total: 0.13780738 | loss total: 0.06704785 |\n",
      "|       | batch  90 | correct total: 0.13667582 | loss total: 0.06711343 |\n",
      "|       | batch 120 | correct total: 0.13946281 | loss total: 0.06709103 |\n",
      "|       | batch 150 | correct total: 0.13990066 | loss total: 0.06708618 |\n",
      "|       | batch 180 | correct total: 0.14174724 | loss total: 0.06706075 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06748136 | 869.97 sec |\n",
      "---------------------------- Epoch 17 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14112903 | loss total: 0.06692873 |\n",
      "|       | batch  60 | correct total: 0.13729508 | loss total: 0.06706900 |\n",
      "|       | batch  90 | correct total: 0.13873626 | loss total: 0.06692189 |\n",
      "|       | batch 120 | correct total: 0.13868802 | loss total: 0.06701914 |\n",
      "|       | batch 150 | correct total: 0.14176325 | loss total: 0.06699251 |\n",
      "|       | batch 180 | correct total: 0.14053867 | loss total: 0.06699304 |\n",
      "| test  | accuracy: 0.1263 | loss avg: 0.06910732 | 921.23 sec |\n",
      "---------------------------- Epoch 18 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16532258 | loss total: 0.06693900 |\n",
      "|       | batch  60 | correct total: 0.16290984 | loss total: 0.06679257 |\n",
      "|       | batch  90 | correct total: 0.15384615 | loss total: 0.06680936 |\n",
      "|       | batch 120 | correct total: 0.15211777 | loss total: 0.06687965 |\n",
      "|       | batch 150 | correct total: 0.14879967 | loss total: 0.06699140 |\n",
      "|       | batch 180 | correct total: 0.14554558 | loss total: 0.06700325 |\n",
      "| test  | accuracy: 0.1168 | loss avg: 0.06884204 | 972.62 sec |\n",
      "---------------------------- Epoch 19 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13608871 | loss total: 0.06701275 |\n",
      "|       | batch  60 | correct total: 0.13370902 | loss total: 0.06696433 |\n",
      "|       | batch  90 | correct total: 0.13427198 | loss total: 0.06704044 |\n",
      "|       | batch 120 | correct total: 0.13868802 | loss total: 0.06703685 |\n",
      "|       | batch 150 | correct total: 0.13886589 | loss total: 0.06698482 |\n",
      "|       | batch 180 | correct total: 0.14036602 | loss total: 0.06700368 |\n",
      "| test  | accuracy: 0.1283 | loss avg: 0.06797343 | 1023.77 sec |\n",
      "---------------------------- Epoch 20 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14717742 | loss total: 0.06707871 |\n",
      "|       | batch  60 | correct total: 0.14344262 | loss total: 0.06694993 |\n",
      "|       | batch  90 | correct total: 0.14457418 | loss total: 0.06694047 |\n",
      "|       | batch 120 | correct total: 0.14514463 | loss total: 0.06694187 |\n",
      "|       | batch 150 | correct total: 0.14528146 | loss total: 0.06695130 |\n",
      "|       | batch 180 | correct total: 0.14278315 | loss total: 0.06694126 |\n",
      "| test  | accuracy: 0.1337 | loss avg: 0.06795698 | 1075.02 sec |\n",
      "---------------------------- Epoch 21 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14112903 | loss total: 0.06708862 |\n",
      "|       | batch  60 | correct total: 0.13268443 | loss total: 0.06717825 |\n",
      "|       | batch  90 | correct total: 0.13461538 | loss total: 0.06707036 |\n",
      "|       | batch 120 | correct total: 0.13868802 | loss total: 0.06699842 |\n",
      "|       | batch 150 | correct total: 0.14114238 | loss total: 0.06693357 |\n",
      "|       | batch 180 | correct total: 0.14278315 | loss total: 0.06690141 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06840630 | 1126.07 sec |\n",
      "---------------------------- Epoch 22 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14818548 | loss total: 0.06688740 |\n",
      "|       | batch  60 | correct total: 0.13268443 | loss total: 0.06682307 |\n",
      "|       | batch  90 | correct total: 0.13701923 | loss total: 0.06673070 |\n",
      "|       | batch 120 | correct total: 0.13997934 | loss total: 0.06685316 |\n",
      "|       | batch 150 | correct total: 0.13762417 | loss total: 0.06687573 |\n",
      "|       | batch 180 | correct total: 0.14174724 | loss total: 0.06684235 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06917169 | 1177.34 sec |\n",
      "---------------------------- Epoch 23 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15423387 | loss total: 0.06661495 |\n",
      "|       | batch  60 | correct total: 0.15881148 | loss total: 0.06682501 |\n",
      "|       | batch  90 | correct total: 0.15418956 | loss total: 0.06692576 |\n",
      "|       | batch 120 | correct total: 0.14901860 | loss total: 0.06688139 |\n",
      "|       | batch 150 | correct total: 0.15045530 | loss total: 0.06688014 |\n",
      "|       | batch 180 | correct total: 0.14951657 | loss total: 0.06683109 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06767978 | 1229.44 sec |\n",
      "---------------------------- Epoch 24 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14818548 | loss total: 0.06660591 |\n",
      "|       | batch  60 | correct total: 0.14344262 | loss total: 0.06688328 |\n",
      "|       | batch  90 | correct total: 0.14800824 | loss total: 0.06685109 |\n",
      "|       | batch 120 | correct total: 0.14514463 | loss total: 0.06683462 |\n",
      "|       | batch 150 | correct total: 0.14383278 | loss total: 0.06684012 |\n",
      "|       | batch 180 | correct total: 0.14640884 | loss total: 0.06681321 |\n",
      "| test  | accuracy: 0.1527 | loss avg: 0.06846009 | 1280.83 sec |\n",
      "---------------------------- Epoch 25 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13104839 | loss total: 0.06704622 |\n",
      "|       | batch  60 | correct total: 0.13114754 | loss total: 0.06698735 |\n",
      "|       | batch  90 | correct total: 0.13633242 | loss total: 0.06686691 |\n",
      "|       | batch 120 | correct total: 0.13688017 | loss total: 0.06688750 |\n",
      "|       | batch 150 | correct total: 0.13969371 | loss total: 0.06682003 |\n",
      "|       | batch 180 | correct total: 0.14157459 | loss total: 0.06679151 |\n",
      "| test  | accuracy: 0.1270 | loss avg: 0.07013979 | 1332.28 sec |\n",
      "---------------------------- Epoch 26 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15725806 | loss total: 0.06662843 |\n",
      "|       | batch  60 | correct total: 0.14856557 | loss total: 0.06656115 |\n",
      "|       | batch  90 | correct total: 0.15109890 | loss total: 0.06660184 |\n",
      "|       | batch 120 | correct total: 0.15005165 | loss total: 0.06664574 |\n",
      "|       | batch 150 | correct total: 0.14610927 | loss total: 0.06671389 |\n",
      "|       | batch 180 | correct total: 0.14623619 | loss total: 0.06671971 |\n",
      "| test  | accuracy: 0.1371 | loss avg: 0.06906077 | 1383.59 sec |\n",
      "---------------------------- Epoch 27 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16028226 | loss total: 0.06687414 |\n",
      "|       | batch  60 | correct total: 0.16393443 | loss total: 0.06666192 |\n",
      "|       | batch  90 | correct total: 0.15384615 | loss total: 0.06681483 |\n",
      "|       | batch 120 | correct total: 0.15030992 | loss total: 0.06679165 |\n",
      "|       | batch 150 | correct total: 0.14610927 | loss total: 0.06683050 |\n",
      "|       | batch 180 | correct total: 0.14640884 | loss total: 0.06673284 |\n",
      "| test  | accuracy: 0.1371 | loss avg: 0.06791433 | 1434.37 sec |\n",
      "---------------------------- Epoch 28 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15524194 | loss total: 0.06654116 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | batch  60 | correct total: 0.14600410 | loss total: 0.06661692 |\n",
      "|       | batch  90 | correct total: 0.14388736 | loss total: 0.06676784 |\n",
      "|       | batch 120 | correct total: 0.14669421 | loss total: 0.06676499 |\n",
      "|       | batch 150 | correct total: 0.14755795 | loss total: 0.06673174 |\n",
      "|       | batch 180 | correct total: 0.14882597 | loss total: 0.06669942 |\n",
      "| test  | accuracy: 0.1378 | loss avg: 0.06973346 | 1484.89 sec |\n",
      "---------------------------- Epoch 29 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14213710 | loss total: 0.06666962 |\n",
      "|       | batch  60 | correct total: 0.14754098 | loss total: 0.06654772 |\n",
      "|       | batch  90 | correct total: 0.14182692 | loss total: 0.06659339 |\n",
      "|       | batch 120 | correct total: 0.14204545 | loss total: 0.06662123 |\n",
      "|       | batch 150 | correct total: 0.14362583 | loss total: 0.06665968 |\n",
      "|       | batch 180 | correct total: 0.14554558 | loss total: 0.06663151 |\n",
      "| test  | accuracy: 0.1371 | loss avg: 0.07032643 | 1535.74 sec |\n",
      "---------------------------- Epoch 30 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14919355 | loss total: 0.06646580 |\n",
      "|       | batch  60 | correct total: 0.14959016 | loss total: 0.06655987 |\n",
      "|       | batch  90 | correct total: 0.15178571 | loss total: 0.06657618 |\n",
      "|       | batch 120 | correct total: 0.15237603 | loss total: 0.06659669 |\n",
      "|       | batch 150 | correct total: 0.15252483 | loss total: 0.06665080 |\n",
      "|       | batch 180 | correct total: 0.14968923 | loss total: 0.06664046 |\n",
      "| test  | accuracy: 0.1466 | loss avg: 0.06743466 | 1587.55 sec |\n",
      "---------------------------- Epoch 31 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13810484 | loss total: 0.06669214 |\n",
      "|       | batch  60 | correct total: 0.13883197 | loss total: 0.06672557 |\n",
      "|       | batch  90 | correct total: 0.14354396 | loss total: 0.06667942 |\n",
      "|       | batch 120 | correct total: 0.14282025 | loss total: 0.06668582 |\n",
      "|       | batch 150 | correct total: 0.14238411 | loss total: 0.06663970 |\n",
      "|       | batch 180 | correct total: 0.14140193 | loss total: 0.06666472 |\n",
      "| test  | accuracy: 0.1365 | loss avg: 0.07077285 | 1638.29 sec |\n",
      "---------------------------- Epoch 32 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15120968 | loss total: 0.06640037 |\n",
      "|       | batch  60 | correct total: 0.14907787 | loss total: 0.06635887 |\n",
      "|       | batch  90 | correct total: 0.14182692 | loss total: 0.06642066 |\n",
      "|       | batch 120 | correct total: 0.13610537 | loss total: 0.06652863 |\n",
      "|       | batch 150 | correct total: 0.13741722 | loss total: 0.06656622 |\n",
      "|       | batch 180 | correct total: 0.14174724 | loss total: 0.06658117 |\n",
      "| test  | accuracy: 0.1331 | loss avg: 0.06850456 | 1689.81 sec |\n",
      "---------------------------- Epoch 33 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14112903 | loss total: 0.06635123 |\n",
      "|       | batch  60 | correct total: 0.13678279 | loss total: 0.06647330 |\n",
      "|       | batch  90 | correct total: 0.14251374 | loss total: 0.06644381 |\n",
      "|       | batch 120 | correct total: 0.14075413 | loss total: 0.06651285 |\n",
      "|       | batch 150 | correct total: 0.14010762 | loss total: 0.06652033 |\n",
      "|       | batch 180 | correct total: 0.14347376 | loss total: 0.06657823 |\n",
      "| test  | accuracy: 0.1195 | loss avg: 0.06858182 | 1741.50 sec |\n",
      "---------------------------- Epoch 34 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13205645 | loss total: 0.06670288 |\n",
      "|       | batch  60 | correct total: 0.14088115 | loss total: 0.06650719 |\n",
      "|       | batch  90 | correct total: 0.13118132 | loss total: 0.06657863 |\n",
      "|       | batch 120 | correct total: 0.13610537 | loss total: 0.06660070 |\n",
      "|       | batch 150 | correct total: 0.13638245 | loss total: 0.06660839 |\n",
      "|       | batch 180 | correct total: 0.13743094 | loss total: 0.06662340 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06923977 | 1792.45 sec |\n",
      "---------------------------- Epoch 35 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15927419 | loss total: 0.06608390 |\n",
      "|       | batch  60 | correct total: 0.15010246 | loss total: 0.06638144 |\n",
      "|       | batch  90 | correct total: 0.15350275 | loss total: 0.06649768 |\n",
      "|       | batch 120 | correct total: 0.15108471 | loss total: 0.06653663 |\n",
      "|       | batch 150 | correct total: 0.14631623 | loss total: 0.06657139 |\n",
      "|       | batch 180 | correct total: 0.14589088 | loss total: 0.06659042 |\n",
      "| test  | accuracy: 0.1385 | loss avg: 0.06720914 | 1843.10 sec |\n",
      "---------------------------- Epoch 36 ----------------------------\n",
      "|       | batch  30 | correct total: 0.12802419 | loss total: 0.06651851 |\n",
      "|       | batch  60 | correct total: 0.13165984 | loss total: 0.06658646 |\n",
      "|       | batch  90 | correct total: 0.13152473 | loss total: 0.06676756 |\n",
      "|       | batch 120 | correct total: 0.13868802 | loss total: 0.06666134 |\n",
      "|       | batch 150 | correct total: 0.14010762 | loss total: 0.06661999 |\n",
      "|       | batch 180 | correct total: 0.14174724 | loss total: 0.06659026 |\n",
      "| test  | accuracy: 0.1521 | loss avg: 0.06722233 | 1893.82 sec |\n",
      "---------------------------- Epoch 37 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16129032 | loss total: 0.06666244 |\n",
      "|       | batch  60 | correct total: 0.14600410 | loss total: 0.06669042 |\n",
      "|       | batch  90 | correct total: 0.14526099 | loss total: 0.06673838 |\n",
      "|       | batch 120 | correct total: 0.14540289 | loss total: 0.06666273 |\n",
      "|       | batch 150 | correct total: 0.14879967 | loss total: 0.06663616 |\n",
      "|       | batch 180 | correct total: 0.14882597 | loss total: 0.06667443 |\n",
      "| test  | accuracy: 0.1324 | loss avg: 0.06938458 | 1944.96 sec |\n",
      "---------------------------- Epoch 38 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13407258 | loss total: 0.06667174 |\n",
      "|       | batch  60 | correct total: 0.15061475 | loss total: 0.06651455 |\n",
      "|       | batch  90 | correct total: 0.14526099 | loss total: 0.06655553 |\n",
      "|       | batch 120 | correct total: 0.14230372 | loss total: 0.06652164 |\n",
      "|       | batch 150 | correct total: 0.14217715 | loss total: 0.06659677 |\n",
      "|       | batch 180 | correct total: 0.14261050 | loss total: 0.06657661 |\n",
      "| test  | accuracy: 0.1283 | loss avg: 0.06966067 | 1995.98 sec |\n",
      "---------------------------- Epoch 39 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13810484 | loss total: 0.06667182 |\n",
      "|       | batch  60 | correct total: 0.13678279 | loss total: 0.06659152 |\n",
      "|       | batch  90 | correct total: 0.13770604 | loss total: 0.06654642 |\n",
      "|       | batch 120 | correct total: 0.13662190 | loss total: 0.06648596 |\n",
      "|       | batch 150 | correct total: 0.13865894 | loss total: 0.06653171 |\n",
      "|       | batch 180 | correct total: 0.13933011 | loss total: 0.06656499 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06869401 | 2047.38 sec |\n",
      "---------------------------- Epoch 40 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15120968 | loss total: 0.06643919 |\n",
      "|       | batch  60 | correct total: 0.15983607 | loss total: 0.06636361 |\n",
      "|       | batch  90 | correct total: 0.15899725 | loss total: 0.06634558 |\n",
      "|       | batch 120 | correct total: 0.15521694 | loss total: 0.06644584 |\n",
      "|       | batch 150 | correct total: 0.15149007 | loss total: 0.06647405 |\n",
      "|       | batch 180 | correct total: 0.14899862 | loss total: 0.06646562 |\n",
      "| test  | accuracy: 0.1521 | loss avg: 0.07010484 | 2098.99 sec |\n",
      "---------------------------- Epoch 41 ----------------------------\n",
      "|       | batch  30 | correct total: 0.12701613 | loss total: 0.06648774 |\n",
      "|       | batch  60 | correct total: 0.14293033 | loss total: 0.06647226 |\n",
      "|       | batch  90 | correct total: 0.14732143 | loss total: 0.06651580 |\n",
      "|       | batch 120 | correct total: 0.14643595 | loss total: 0.06662385 |\n",
      "|       | batch 150 | correct total: 0.14652318 | loss total: 0.06659542 |\n",
      "|       | batch 180 | correct total: 0.14088398 | loss total: 0.06658358 |\n",
      "| test  | accuracy: 0.1534 | loss avg: 0.06722814 | 2149.24 sec |\n",
      "---------------------------- Epoch 42 ----------------------------\n",
      "|       | batch  30 | correct total: 0.11693548 | loss total: 0.06661015 |\n",
      "|       | batch  60 | correct total: 0.12448770 | loss total: 0.06645627 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | batch  90 | correct total: 0.13358516 | loss total: 0.06643648 |\n",
      "|       | batch 120 | correct total: 0.13403926 | loss total: 0.06643014 |\n",
      "|       | batch 150 | correct total: 0.13410596 | loss total: 0.06645534 |\n",
      "|       | batch 180 | correct total: 0.13535912 | loss total: 0.06645938 |\n",
      "| test  | accuracy: 0.1358 | loss avg: 0.06864580 | 2200.55 sec |\n",
      "---------------------------- Epoch 43 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16028226 | loss total: 0.06646713 |\n",
      "|       | batch  60 | correct total: 0.14959016 | loss total: 0.06634947 |\n",
      "|       | batch  90 | correct total: 0.14697802 | loss total: 0.06639752 |\n",
      "|       | batch 120 | correct total: 0.14695248 | loss total: 0.06643059 |\n",
      "|       | batch 150 | correct total: 0.14797185 | loss total: 0.06649540 |\n",
      "|       | batch 180 | correct total: 0.14640884 | loss total: 0.06649175 |\n",
      "| test  | accuracy: 0.1507 | loss avg: 0.06709253 | 2252.35 sec |\n",
      "---------------------------- Epoch 44 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13407258 | loss total: 0.06638266 |\n",
      "|       | batch  60 | correct total: 0.14395492 | loss total: 0.06636883 |\n",
      "|       | batch  90 | correct total: 0.14697802 | loss total: 0.06634423 |\n",
      "|       | batch 120 | correct total: 0.14514463 | loss total: 0.06637473 |\n",
      "|       | batch 150 | correct total: 0.14093543 | loss total: 0.06641495 |\n",
      "|       | batch 180 | correct total: 0.14381906 | loss total: 0.06644800 |\n",
      "| test  | accuracy: 0.1256 | loss avg: 0.06880598 | 2304.24 sec |\n",
      "---------------------------- Epoch 45 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15020161 | loss total: 0.06657790 |\n",
      "|       | batch  60 | correct total: 0.14805328 | loss total: 0.06655273 |\n",
      "|       | batch  90 | correct total: 0.14766484 | loss total: 0.06658177 |\n",
      "|       | batch 120 | correct total: 0.14746901 | loss total: 0.06656221 |\n",
      "|       | batch 150 | correct total: 0.14548841 | loss total: 0.06654984 |\n",
      "|       | batch 180 | correct total: 0.14692680 | loss total: 0.06648816 |\n",
      "| test  | accuracy: 0.1337 | loss avg: 0.06783739 | 2355.84 sec |\n",
      "---------------------------- Epoch 46 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15020161 | loss total: 0.06658648 |\n",
      "|       | batch  60 | correct total: 0.14805328 | loss total: 0.06645625 |\n",
      "|       | batch  90 | correct total: 0.14972527 | loss total: 0.06635010 |\n",
      "|       | batch 120 | correct total: 0.14824380 | loss total: 0.06647464 |\n",
      "|       | batch 150 | correct total: 0.14486755 | loss total: 0.06655923 |\n",
      "|       | batch 180 | correct total: 0.14468232 | loss total: 0.06651745 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06973357 | 2407.00 sec |\n",
      "---------------------------- Epoch 47 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14213710 | loss total: 0.06647914 |\n",
      "|       | batch  60 | correct total: 0.14907787 | loss total: 0.06640140 |\n",
      "|       | batch  90 | correct total: 0.14594780 | loss total: 0.06653597 |\n",
      "|       | batch 120 | correct total: 0.14746901 | loss total: 0.06655040 |\n",
      "|       | batch 150 | correct total: 0.14590232 | loss total: 0.06658497 |\n",
      "|       | batch 180 | correct total: 0.14295580 | loss total: 0.06652582 |\n",
      "| test  | accuracy: 0.1460 | loss avg: 0.06874417 | 2458.12 sec |\n",
      "---------------------------- Epoch 48 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14415323 | loss total: 0.06623863 |\n",
      "|       | batch  60 | correct total: 0.13934426 | loss total: 0.06638637 |\n",
      "|       | batch  90 | correct total: 0.14114011 | loss total: 0.06645226 |\n",
      "|       | batch 120 | correct total: 0.14566116 | loss total: 0.06641985 |\n",
      "|       | batch 150 | correct total: 0.14507450 | loss total: 0.06648954 |\n",
      "|       | batch 180 | correct total: 0.14744475 | loss total: 0.06647711 |\n",
      "| test  | accuracy: 0.1365 | loss avg: 0.06847733 | 2509.31 sec |\n",
      "---------------------------- Epoch 49 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14717742 | loss total: 0.06663681 |\n",
      "|       | batch  60 | correct total: 0.14702869 | loss total: 0.06650508 |\n",
      "|       | batch  90 | correct total: 0.14835165 | loss total: 0.06644473 |\n",
      "|       | batch 120 | correct total: 0.14566116 | loss total: 0.06644937 |\n",
      "|       | batch 150 | correct total: 0.14548841 | loss total: 0.06645126 |\n",
      "|       | batch 180 | correct total: 0.14381906 | loss total: 0.06645027 |\n",
      "| test  | accuracy: 0.1371 | loss avg: 0.06881978 | 2560.62 sec |\n",
      "---------------------------- Epoch 50 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15322581 | loss total: 0.06599982 |\n",
      "|       | batch  60 | correct total: 0.14600410 | loss total: 0.06628842 |\n",
      "|       | batch  90 | correct total: 0.15418956 | loss total: 0.06629794 |\n",
      "|       | batch 120 | correct total: 0.15547521 | loss total: 0.06632303 |\n",
      "|       | batch 150 | correct total: 0.15128311 | loss total: 0.06637002 |\n",
      "|       | batch 180 | correct total: 0.14433702 | loss total: 0.06647121 |\n",
      "| test  | accuracy: 0.1236 | loss avg: 0.06713074 | 2611.31 sec |\n",
      "---------------------------- Epoch 51 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15826613 | loss total: 0.06645308 |\n",
      "|       | batch  60 | correct total: 0.14959016 | loss total: 0.06653632 |\n",
      "|       | batch  90 | correct total: 0.14388736 | loss total: 0.06656325 |\n",
      "|       | batch 120 | correct total: 0.14566116 | loss total: 0.06651422 |\n",
      "|       | batch 150 | correct total: 0.14776490 | loss total: 0.06646939 |\n",
      "|       | batch 180 | correct total: 0.14520028 | loss total: 0.06645486 |\n",
      "| test  | accuracy: 0.1399 | loss avg: 0.07079096 | 2662.58 sec |\n",
      "---------------------------- Epoch 52 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15423387 | loss total: 0.06632116 |\n",
      "|       | batch  60 | correct total: 0.14959016 | loss total: 0.06634731 |\n",
      "|       | batch  90 | correct total: 0.14285714 | loss total: 0.06645132 |\n",
      "|       | batch 120 | correct total: 0.13791322 | loss total: 0.06645369 |\n",
      "|       | batch 150 | correct total: 0.14217715 | loss total: 0.06640564 |\n",
      "|       | batch 180 | correct total: 0.14261050 | loss total: 0.06642887 |\n",
      "| test  | accuracy: 0.1399 | loss avg: 0.06893993 | 2713.58 sec |\n",
      "---------------------------- Epoch 53 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15221774 | loss total: 0.06654882 |\n",
      "|       | batch  60 | correct total: 0.14036885 | loss total: 0.06655295 |\n",
      "|       | batch  90 | correct total: 0.14320055 | loss total: 0.06654094 |\n",
      "|       | batch 120 | correct total: 0.14307851 | loss total: 0.06651190 |\n",
      "|       | batch 150 | correct total: 0.14486755 | loss total: 0.06641633 |\n",
      "|       | batch 180 | correct total: 0.14433702 | loss total: 0.06643448 |\n",
      "| test  | accuracy: 0.1358 | loss avg: 0.06886721 | 2765.23 sec |\n",
      "---------------------------- Epoch 54 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13911290 | loss total: 0.06682349 |\n",
      "|       | batch  60 | correct total: 0.14959016 | loss total: 0.06649353 |\n",
      "|       | batch  90 | correct total: 0.14491758 | loss total: 0.06646419 |\n",
      "|       | batch 120 | correct total: 0.14901860 | loss total: 0.06638934 |\n",
      "|       | batch 150 | correct total: 0.14983444 | loss total: 0.06646489 |\n",
      "|       | batch 180 | correct total: 0.14917127 | loss total: 0.06646213 |\n",
      "| test  | accuracy: 0.1297 | loss avg: 0.06740534 | 2816.09 sec |\n",
      "---------------------------- Epoch 55 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15625000 | loss total: 0.06663685 |\n",
      "|       | batch  60 | correct total: 0.16290984 | loss total: 0.06635900 |\n",
      "|       | batch  90 | correct total: 0.15693681 | loss total: 0.06642358 |\n",
      "|       | batch 120 | correct total: 0.15056818 | loss total: 0.06648573 |\n",
      "|       | batch 150 | correct total: 0.15024834 | loss total: 0.06648199 |\n",
      "|       | batch 180 | correct total: 0.14951657 | loss total: 0.06644441 |\n",
      "| test  | accuracy: 0.1385 | loss avg: 0.06733795 | 2867.33 sec |\n",
      "---------------------------- Epoch 56 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15423387 | loss total: 0.06627600 |\n",
      "|       | batch  60 | correct total: 0.16239754 | loss total: 0.06634633 |\n",
      "|       | batch  90 | correct total: 0.15762363 | loss total: 0.06631290 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | batch 120 | correct total: 0.15599174 | loss total: 0.06643444 |\n",
      "|       | batch 150 | correct total: 0.15231788 | loss total: 0.06639110 |\n",
      "|       | batch 180 | correct total: 0.15003453 | loss total: 0.06641311 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.07001772 | 2918.34 sec |\n",
      "---------------------------- Epoch 57 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16129032 | loss total: 0.06660132 |\n",
      "|       | batch  60 | correct total: 0.15573770 | loss total: 0.06647793 |\n",
      "|       | batch  90 | correct total: 0.14938187 | loss total: 0.06643094 |\n",
      "|       | batch 120 | correct total: 0.14953512 | loss total: 0.06640308 |\n",
      "|       | batch 150 | correct total: 0.14921358 | loss total: 0.06643915 |\n",
      "|       | batch 180 | correct total: 0.14692680 | loss total: 0.06646080 |\n",
      "| test  | accuracy: 0.1236 | loss avg: 0.06753525 | 2969.04 sec |\n",
      "---------------------------- Epoch 58 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14818548 | loss total: 0.06617500 |\n",
      "|       | batch  60 | correct total: 0.14600410 | loss total: 0.06636212 |\n",
      "|       | batch  90 | correct total: 0.14423077 | loss total: 0.06637482 |\n",
      "|       | batch 120 | correct total: 0.14540289 | loss total: 0.06639141 |\n",
      "|       | batch 150 | correct total: 0.14362583 | loss total: 0.06638143 |\n",
      "|       | batch 180 | correct total: 0.14520028 | loss total: 0.06638676 |\n",
      "| test  | accuracy: 0.1358 | loss avg: 0.06789306 | 3020.22 sec |\n",
      "---------------------------- Epoch 59 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13205645 | loss total: 0.06637597 |\n",
      "|       | batch  60 | correct total: 0.14344262 | loss total: 0.06639949 |\n",
      "|       | batch  90 | correct total: 0.14697802 | loss total: 0.06640539 |\n",
      "|       | batch 120 | correct total: 0.14695248 | loss total: 0.06640980 |\n",
      "|       | batch 150 | correct total: 0.14403974 | loss total: 0.06645784 |\n",
      "|       | batch 180 | correct total: 0.14606354 | loss total: 0.06642446 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.07028760 | 3071.26 sec |\n",
      "---------------------------- Epoch 60 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16129032 | loss total: 0.06636530 |\n",
      "|       | batch  60 | correct total: 0.15471311 | loss total: 0.06640845 |\n",
      "|       | batch  90 | correct total: 0.15178571 | loss total: 0.06644902 |\n",
      "|       | batch 120 | correct total: 0.14462810 | loss total: 0.06647289 |\n",
      "|       | batch 150 | correct total: 0.14321192 | loss total: 0.06643557 |\n",
      "|       | batch 180 | correct total: 0.14347376 | loss total: 0.06642277 |\n",
      "| test  | accuracy: 0.1195 | loss avg: 0.06741583 | 3122.55 sec |\n",
      "---------------------------- Epoch 61 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13810484 | loss total: 0.06648289 |\n",
      "|       | batch  60 | correct total: 0.14651639 | loss total: 0.06640683 |\n",
      "|       | batch  90 | correct total: 0.14972527 | loss total: 0.06640378 |\n",
      "|       | batch 120 | correct total: 0.15237603 | loss total: 0.06638551 |\n",
      "|       | batch 150 | correct total: 0.15149007 | loss total: 0.06640821 |\n",
      "|       | batch 180 | correct total: 0.15141575 | loss total: 0.06640469 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06995701 | 3173.76 sec |\n",
      "---------------------------- Epoch 62 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13709677 | loss total: 0.06668200 |\n",
      "|       | batch  60 | correct total: 0.13780738 | loss total: 0.06640816 |\n",
      "|       | batch  90 | correct total: 0.14251374 | loss total: 0.06633203 |\n",
      "|       | batch 120 | correct total: 0.14049587 | loss total: 0.06638794 |\n",
      "|       | batch 150 | correct total: 0.14300497 | loss total: 0.06638261 |\n",
      "|       | batch 180 | correct total: 0.14813536 | loss total: 0.06635131 |\n",
      "| test  | accuracy: 0.1310 | loss avg: 0.06751501 | 3224.60 sec |\n",
      "---------------------------- Epoch 63 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14213710 | loss total: 0.06647075 |\n",
      "|       | batch  60 | correct total: 0.14805328 | loss total: 0.06647501 |\n",
      "|       | batch  90 | correct total: 0.14800824 | loss total: 0.06647946 |\n",
      "|       | batch 120 | correct total: 0.14669421 | loss total: 0.06643688 |\n",
      "|       | batch 150 | correct total: 0.14755795 | loss total: 0.06640669 |\n",
      "|       | batch 180 | correct total: 0.14779006 | loss total: 0.06639817 |\n",
      "| test  | accuracy: 0.1392 | loss avg: 0.06991250 | 3275.25 sec |\n",
      "---------------------------- Epoch 64 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15725806 | loss total: 0.06632169 |\n",
      "|       | batch  60 | correct total: 0.15010246 | loss total: 0.06651024 |\n",
      "|       | batch  90 | correct total: 0.15041209 | loss total: 0.06637174 |\n",
      "|       | batch 120 | correct total: 0.14901860 | loss total: 0.06631474 |\n",
      "|       | batch 150 | correct total: 0.15231788 | loss total: 0.06633934 |\n",
      "|       | batch 180 | correct total: 0.15193370 | loss total: 0.06637326 |\n",
      "| test  | accuracy: 0.1392 | loss avg: 0.06906216 | 3326.14 sec |\n",
      "---------------------------- Epoch 65 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13508065 | loss total: 0.06642344 |\n",
      "|       | batch  60 | correct total: 0.13575820 | loss total: 0.06645003 |\n",
      "|       | batch  90 | correct total: 0.13942308 | loss total: 0.06632514 |\n",
      "|       | batch 120 | correct total: 0.13894628 | loss total: 0.06641153 |\n",
      "|       | batch 150 | correct total: 0.14031457 | loss total: 0.06645836 |\n",
      "|       | batch 180 | correct total: 0.14088398 | loss total: 0.06643301 |\n",
      "| test  | accuracy: 0.1378 | loss avg: 0.06942257 | 3376.68 sec |\n",
      "---------------------------- Epoch 66 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15625000 | loss total: 0.06645381 |\n",
      "|       | batch  60 | correct total: 0.14959016 | loss total: 0.06641842 |\n",
      "|       | batch  90 | correct total: 0.15796703 | loss total: 0.06634529 |\n",
      "|       | batch 120 | correct total: 0.15779959 | loss total: 0.06636117 |\n",
      "|       | batch 150 | correct total: 0.15562914 | loss total: 0.06637902 |\n",
      "|       | batch 180 | correct total: 0.15348757 | loss total: 0.06640594 |\n",
      "| test  | accuracy: 0.1236 | loss avg: 0.06747719 | 3427.75 sec |\n",
      "---------------------------- Epoch 67 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13810484 | loss total: 0.06640682 |\n",
      "|       | batch  60 | correct total: 0.14805328 | loss total: 0.06646500 |\n",
      "|       | batch  90 | correct total: 0.14560440 | loss total: 0.06648956 |\n",
      "|       | batch 120 | correct total: 0.14850207 | loss total: 0.06639698 |\n",
      "|       | batch 150 | correct total: 0.14797185 | loss total: 0.06640420 |\n",
      "|       | batch 180 | correct total: 0.14796271 | loss total: 0.06640056 |\n",
      "| test  | accuracy: 0.1412 | loss avg: 0.06895305 | 3478.96 sec |\n",
      "---------------------------- Epoch 68 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14314516 | loss total: 0.06613610 |\n",
      "|       | batch  60 | correct total: 0.14651639 | loss total: 0.06644472 |\n",
      "|       | batch  90 | correct total: 0.14663462 | loss total: 0.06642338 |\n",
      "|       | batch 120 | correct total: 0.14721074 | loss total: 0.06639816 |\n",
      "|       | batch 150 | correct total: 0.14569536 | loss total: 0.06637984 |\n",
      "|       | batch 180 | correct total: 0.14416436 | loss total: 0.06640383 |\n",
      "| test  | accuracy: 0.1399 | loss avg: 0.06720230 | 3530.35 sec |\n",
      "---------------------------- Epoch 69 ----------------------------\n",
      "|       | batch  30 | correct total: 0.17741935 | loss total: 0.06589860 |\n",
      "|       | batch  60 | correct total: 0.17059426 | loss total: 0.06607348 |\n",
      "|       | batch  90 | correct total: 0.16140110 | loss total: 0.06623803 |\n",
      "|       | batch 120 | correct total: 0.16012397 | loss total: 0.06626863 |\n",
      "|       | batch 150 | correct total: 0.15645695 | loss total: 0.06628377 |\n",
      "|       | batch 180 | correct total: 0.15417818 | loss total: 0.06628837 |\n",
      "| test  | accuracy: 0.1270 | loss avg: 0.06972940 | 3581.15 sec |\n",
      "---------------------------- Epoch 70 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15524194 | loss total: 0.06645213 |\n",
      "|       | batch  60 | correct total: 0.15983607 | loss total: 0.06655174 |\n",
      "|       | batch  90 | correct total: 0.15831044 | loss total: 0.06644082 |\n",
      "|       | batch 120 | correct total: 0.15909091 | loss total: 0.06636604 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | batch 150 | correct total: 0.15521523 | loss total: 0.06638498 |\n",
      "|       | batch 180 | correct total: 0.15314227 | loss total: 0.06640568 |\n",
      "| test  | accuracy: 0.1534 | loss avg: 0.06734338 | 3632.38 sec |\n",
      "---------------------------- Epoch 71 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14717742 | loss total: 0.06636457 |\n",
      "|       | batch  60 | correct total: 0.14805328 | loss total: 0.06636694 |\n",
      "|       | batch  90 | correct total: 0.14732143 | loss total: 0.06639100 |\n",
      "|       | batch 120 | correct total: 0.14669421 | loss total: 0.06639099 |\n",
      "|       | batch 150 | correct total: 0.14735099 | loss total: 0.06639849 |\n",
      "|       | batch 180 | correct total: 0.14589088 | loss total: 0.06637039 |\n",
      "| test  | accuracy: 0.1439 | loss avg: 0.06716485 | 3683.60 sec |\n",
      "---------------------------- Epoch 72 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13810484 | loss total: 0.06618183 |\n",
      "|       | batch  60 | correct total: 0.13883197 | loss total: 0.06622936 |\n",
      "|       | batch  90 | correct total: 0.13942308 | loss total: 0.06631322 |\n",
      "|       | batch 120 | correct total: 0.14256198 | loss total: 0.06634533 |\n",
      "|       | batch 150 | correct total: 0.13907285 | loss total: 0.06636436 |\n",
      "|       | batch 180 | correct total: 0.13881215 | loss total: 0.06637510 |\n",
      "| test  | accuracy: 0.1229 | loss avg: 0.06734924 | 3734.70 sec |\n",
      "---------------------------- Epoch 73 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15725806 | loss total: 0.06633718 |\n",
      "|       | batch  60 | correct total: 0.15215164 | loss total: 0.06638793 |\n",
      "|       | batch  90 | correct total: 0.14972527 | loss total: 0.06644401 |\n",
      "|       | batch 120 | correct total: 0.14798554 | loss total: 0.06641805 |\n",
      "|       | batch 150 | correct total: 0.14983444 | loss total: 0.06629864 |\n",
      "|       | batch 180 | correct total: 0.14658149 | loss total: 0.06636539 |\n",
      "| test  | accuracy: 0.1195 | loss avg: 0.06928069 | 3786.21 sec |\n",
      "---------------------------- Epoch 74 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15221774 | loss total: 0.06653606 |\n",
      "|       | batch  60 | correct total: 0.15881148 | loss total: 0.06629301 |\n",
      "|       | batch  90 | correct total: 0.14800824 | loss total: 0.06630249 |\n",
      "|       | batch 120 | correct total: 0.14359504 | loss total: 0.06629927 |\n",
      "|       | batch 150 | correct total: 0.14279801 | loss total: 0.06633127 |\n",
      "|       | batch 180 | correct total: 0.14105663 | loss total: 0.06636812 |\n",
      "| test  | accuracy: 0.1371 | loss avg: 0.06836104 | 3837.29 sec |\n",
      "---------------------------- Epoch 75 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13608871 | loss total: 0.06620978 |\n",
      "|       | batch  60 | correct total: 0.14241803 | loss total: 0.06610603 |\n",
      "|       | batch  90 | correct total: 0.14732143 | loss total: 0.06618547 |\n",
      "|       | batch 120 | correct total: 0.14643595 | loss total: 0.06625307 |\n",
      "|       | batch 150 | correct total: 0.14424669 | loss total: 0.06629381 |\n",
      "|       | batch 180 | correct total: 0.14261050 | loss total: 0.06632475 |\n",
      "| test  | accuracy: 0.1399 | loss avg: 0.06926048 | 3888.22 sec |\n",
      "---------------------------- Epoch 76 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14919355 | loss total: 0.06645303 |\n",
      "|       | batch  60 | correct total: 0.14446721 | loss total: 0.06631223 |\n",
      "|       | batch  90 | correct total: 0.14251374 | loss total: 0.06628338 |\n",
      "|       | batch 120 | correct total: 0.14178719 | loss total: 0.06639529 |\n",
      "|       | batch 150 | correct total: 0.14424669 | loss total: 0.06638938 |\n",
      "|       | batch 180 | correct total: 0.14364641 | loss total: 0.06638639 |\n",
      "| test  | accuracy: 0.1365 | loss avg: 0.06733859 | 3939.07 sec |\n",
      "---------------------------- Epoch 77 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15725806 | loss total: 0.06642801 |\n",
      "|       | batch  60 | correct total: 0.15061475 | loss total: 0.06637532 |\n",
      "|       | batch  90 | correct total: 0.14869505 | loss total: 0.06637278 |\n",
      "|       | batch 120 | correct total: 0.15211777 | loss total: 0.06636691 |\n",
      "|       | batch 150 | correct total: 0.15293874 | loss total: 0.06636449 |\n",
      "|       | batch 180 | correct total: 0.15245166 | loss total: 0.06635372 |\n",
      "| test  | accuracy: 0.1215 | loss avg: 0.06737213 | 3990.26 sec |\n",
      "---------------------------- Epoch 78 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13810484 | loss total: 0.06629951 |\n",
      "|       | batch  60 | correct total: 0.13524590 | loss total: 0.06630277 |\n",
      "|       | batch  90 | correct total: 0.13839286 | loss total: 0.06628021 |\n",
      "|       | batch 120 | correct total: 0.14462810 | loss total: 0.06634271 |\n",
      "|       | batch 150 | correct total: 0.14197020 | loss total: 0.06637522 |\n",
      "|       | batch 180 | correct total: 0.14261050 | loss total: 0.06633029 |\n",
      "| test  | accuracy: 0.1365 | loss avg: 0.06746439 | 4041.22 sec |\n",
      "---------------------------- Epoch 79 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16935484 | loss total: 0.06611988 |\n",
      "|       | batch  60 | correct total: 0.16393443 | loss total: 0.06621062 |\n",
      "|       | batch  90 | correct total: 0.15899725 | loss total: 0.06622986 |\n",
      "|       | batch 120 | correct total: 0.15599174 | loss total: 0.06630191 |\n",
      "|       | batch 150 | correct total: 0.15521523 | loss total: 0.06628107 |\n",
      "|       | batch 180 | correct total: 0.15314227 | loss total: 0.06629966 |\n",
      "| test  | accuracy: 0.1256 | loss avg: 0.06722871 | 4092.43 sec |\n",
      "---------------------------- Epoch 80 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13306452 | loss total: 0.06633880 |\n",
      "|       | batch  60 | correct total: 0.13473361 | loss total: 0.06652701 |\n",
      "|       | batch  90 | correct total: 0.13289835 | loss total: 0.06640518 |\n",
      "|       | batch 120 | correct total: 0.13507231 | loss total: 0.06643569 |\n",
      "|       | batch 150 | correct total: 0.14031457 | loss total: 0.06638125 |\n",
      "|       | batch 180 | correct total: 0.14122928 | loss total: 0.06636630 |\n",
      "| test  | accuracy: 0.1500 | loss avg: 0.06731715 | 4143.86 sec |\n",
      "---------------------------- Epoch 81 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14415323 | loss total: 0.06641888 |\n",
      "|       | batch  60 | correct total: 0.14651639 | loss total: 0.06633775 |\n",
      "|       | batch  90 | correct total: 0.14423077 | loss total: 0.06618816 |\n",
      "|       | batch 120 | correct total: 0.14462810 | loss total: 0.06627499 |\n",
      "|       | batch 150 | correct total: 0.14486755 | loss total: 0.06630225 |\n",
      "|       | batch 180 | correct total: 0.14450967 | loss total: 0.06628925 |\n",
      "| test  | accuracy: 0.1541 | loss avg: 0.06703205 | 4195.15 sec |\n",
      "---------------------------- Epoch 82 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13608871 | loss total: 0.06619467 |\n",
      "|       | batch  60 | correct total: 0.14395492 | loss total: 0.06629579 |\n",
      "|       | batch  90 | correct total: 0.14114011 | loss total: 0.06630989 |\n",
      "|       | batch 120 | correct total: 0.14204545 | loss total: 0.06636710 |\n",
      "|       | batch 150 | correct total: 0.14383278 | loss total: 0.06634719 |\n",
      "|       | batch 180 | correct total: 0.14036602 | loss total: 0.06633852 |\n",
      "| test  | accuracy: 0.1392 | loss avg: 0.06823385 | 4246.62 sec |\n",
      "---------------------------- Epoch 83 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14213710 | loss total: 0.06633474 |\n",
      "|       | batch  60 | correct total: 0.15163934 | loss total: 0.06637557 |\n",
      "|       | batch  90 | correct total: 0.15350275 | loss total: 0.06628276 |\n",
      "|       | batch 120 | correct total: 0.14721074 | loss total: 0.06627213 |\n",
      "|       | batch 150 | correct total: 0.14962748 | loss total: 0.06630930 |\n",
      "|       | batch 180 | correct total: 0.14917127 | loss total: 0.06628062 |\n",
      "| test  | accuracy: 0.1378 | loss avg: 0.06963821 | 4297.98 sec |\n",
      "---------------------------- Epoch 84 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13608871 | loss total: 0.06641602 |\n",
      "|       | batch  60 | correct total: 0.13934426 | loss total: 0.06634781 |\n",
      "|       | batch  90 | correct total: 0.13804945 | loss total: 0.06635985 |\n",
      "|       | batch 120 | correct total: 0.14152893 | loss total: 0.06632653 |\n",
      "|       | batch 150 | correct total: 0.14300497 | loss total: 0.06633227 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | batch 180 | correct total: 0.14589088 | loss total: 0.06632972 |\n",
      "| test  | accuracy: 0.1351 | loss avg: 0.06923423 | 4349.28 sec |\n",
      "---------------------------- Epoch 85 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13508065 | loss total: 0.06644250 |\n",
      "|       | batch  60 | correct total: 0.14754098 | loss total: 0.06630428 |\n",
      "|       | batch  90 | correct total: 0.14491758 | loss total: 0.06633429 |\n",
      "|       | batch 120 | correct total: 0.14746901 | loss total: 0.06631573 |\n",
      "|       | batch 150 | correct total: 0.14921358 | loss total: 0.06630693 |\n",
      "|       | batch 180 | correct total: 0.14727210 | loss total: 0.06633680 |\n",
      "| test  | accuracy: 0.1453 | loss avg: 0.06733219 | 4400.56 sec |\n",
      "---------------------------- Epoch 86 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15826613 | loss total: 0.06648421 |\n",
      "|       | batch  60 | correct total: 0.15471311 | loss total: 0.06642677 |\n",
      "|       | batch  90 | correct total: 0.15109890 | loss total: 0.06635113 |\n",
      "|       | batch 120 | correct total: 0.14746901 | loss total: 0.06632675 |\n",
      "|       | batch 150 | correct total: 0.14942053 | loss total: 0.06633349 |\n",
      "|       | batch 180 | correct total: 0.14951657 | loss total: 0.06632457 |\n",
      "| test  | accuracy: 0.1358 | loss avg: 0.06774092 | 4452.48 sec |\n",
      "---------------------------- Epoch 87 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16129032 | loss total: 0.06627365 |\n",
      "|       | batch  60 | correct total: 0.14856557 | loss total: 0.06637971 |\n",
      "|       | batch  90 | correct total: 0.14800824 | loss total: 0.06635929 |\n",
      "|       | batch 120 | correct total: 0.14901860 | loss total: 0.06641496 |\n",
      "|       | batch 150 | correct total: 0.14673013 | loss total: 0.06641401 |\n",
      "|       | batch 180 | correct total: 0.14727210 | loss total: 0.06636737 |\n",
      "| test  | accuracy: 0.1256 | loss avg: 0.06802353 | 4503.84 sec |\n",
      "---------------------------- Epoch 88 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14818548 | loss total: 0.06608039 |\n",
      "|       | batch  60 | correct total: 0.14446721 | loss total: 0.06622676 |\n",
      "|       | batch  90 | correct total: 0.14560440 | loss total: 0.06631359 |\n",
      "|       | batch 120 | correct total: 0.14824380 | loss total: 0.06630683 |\n",
      "|       | batch 150 | correct total: 0.14693709 | loss total: 0.06627447 |\n",
      "|       | batch 180 | correct total: 0.14796271 | loss total: 0.06630528 |\n",
      "| test  | accuracy: 0.1222 | loss avg: 0.06934515 | 4555.73 sec |\n",
      "---------------------------- Epoch 89 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15423387 | loss total: 0.06640697 |\n",
      "|       | batch  60 | correct total: 0.14856557 | loss total: 0.06635946 |\n",
      "|       | batch  90 | correct total: 0.15178571 | loss total: 0.06639209 |\n",
      "|       | batch 120 | correct total: 0.14979339 | loss total: 0.06639551 |\n",
      "|       | batch 150 | correct total: 0.14755795 | loss total: 0.06636056 |\n",
      "|       | batch 180 | correct total: 0.14709945 | loss total: 0.06635985 |\n",
      "| test  | accuracy: 0.1507 | loss avg: 0.06751319 | 4607.17 sec |\n",
      "---------------------------- Epoch 90 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14516129 | loss total: 0.06611178 |\n",
      "|       | batch  60 | correct total: 0.15163934 | loss total: 0.06609057 |\n",
      "|       | batch  90 | correct total: 0.14869505 | loss total: 0.06625831 |\n",
      "|       | batch 120 | correct total: 0.14824380 | loss total: 0.06629844 |\n",
      "|       | batch 150 | correct total: 0.14569536 | loss total: 0.06630652 |\n",
      "|       | batch 180 | correct total: 0.14727210 | loss total: 0.06629276 |\n",
      "| test  | accuracy: 0.1385 | loss avg: 0.06781987 | 4658.87 sec |\n",
      "---------------------------- Epoch 91 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15423387 | loss total: 0.06633688 |\n",
      "|       | batch  60 | correct total: 0.14805328 | loss total: 0.06630345 |\n",
      "|       | batch  90 | correct total: 0.14560440 | loss total: 0.06629586 |\n",
      "|       | batch 120 | correct total: 0.14798554 | loss total: 0.06637961 |\n",
      "|       | batch 150 | correct total: 0.14817881 | loss total: 0.06637448 |\n",
      "|       | batch 180 | correct total: 0.14571823 | loss total: 0.06635779 |\n",
      "| test  | accuracy: 0.1385 | loss avg: 0.06914330 | 4710.06 sec |\n",
      "---------------------------- Epoch 92 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13205645 | loss total: 0.06608007 |\n",
      "|       | batch  60 | correct total: 0.14395492 | loss total: 0.06616425 |\n",
      "|       | batch  90 | correct total: 0.14697802 | loss total: 0.06623353 |\n",
      "|       | batch 120 | correct total: 0.14850207 | loss total: 0.06621586 |\n",
      "|       | batch 150 | correct total: 0.14797185 | loss total: 0.06626987 |\n",
      "|       | batch 180 | correct total: 0.14571823 | loss total: 0.06628454 |\n",
      "| test  | accuracy: 0.1466 | loss avg: 0.06718962 | 4761.38 sec |\n",
      "---------------------------- Epoch 93 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14415323 | loss total: 0.06622756 |\n",
      "|       | batch  60 | correct total: 0.13985656 | loss total: 0.06633158 |\n",
      "|       | batch  90 | correct total: 0.14010989 | loss total: 0.06637062 |\n",
      "|       | batch 120 | correct total: 0.14101240 | loss total: 0.06634949 |\n",
      "|       | batch 150 | correct total: 0.14548841 | loss total: 0.06631644 |\n",
      "|       | batch 180 | correct total: 0.14727210 | loss total: 0.06630865 |\n",
      "| test  | accuracy: 0.1419 | loss avg: 0.06950507 | 4812.76 sec |\n",
      "---------------------------- Epoch 94 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13407258 | loss total: 0.06613917 |\n",
      "|       | batch  60 | correct total: 0.14702869 | loss total: 0.06617720 |\n",
      "|       | batch  90 | correct total: 0.13701923 | loss total: 0.06621813 |\n",
      "|       | batch 120 | correct total: 0.14075413 | loss total: 0.06627435 |\n",
      "|       | batch 150 | correct total: 0.14590232 | loss total: 0.06627976 |\n",
      "|       | batch 180 | correct total: 0.14779006 | loss total: 0.06630188 |\n",
      "| test  | accuracy: 0.1385 | loss avg: 0.06764800 | 4864.15 sec |\n",
      "---------------------------- Epoch 95 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15221774 | loss total: 0.06660875 |\n",
      "|       | batch  60 | correct total: 0.14600410 | loss total: 0.06652518 |\n",
      "|       | batch  90 | correct total: 0.15075549 | loss total: 0.06638727 |\n",
      "|       | batch 120 | correct total: 0.15185950 | loss total: 0.06635801 |\n",
      "|       | batch 150 | correct total: 0.15004139 | loss total: 0.06636466 |\n",
      "|       | batch 180 | correct total: 0.15245166 | loss total: 0.06634840 |\n",
      "| test  | accuracy: 0.1426 | loss avg: 0.07026968 | 4915.09 sec |\n",
      "---------------------------- Epoch 96 ----------------------------\n",
      "|       | batch  30 | correct total: 0.14717742 | loss total: 0.06640940 |\n",
      "|       | batch  60 | correct total: 0.15215164 | loss total: 0.06627058 |\n",
      "|       | batch  90 | correct total: 0.15041209 | loss total: 0.06629469 |\n",
      "|       | batch 120 | correct total: 0.14876033 | loss total: 0.06631033 |\n",
      "|       | batch 150 | correct total: 0.14673013 | loss total: 0.06630149 |\n",
      "|       | batch 180 | correct total: 0.14917127 | loss total: 0.06628164 |\n",
      "| test  | accuracy: 0.1534 | loss avg: 0.06716372 | 4966.57 sec |\n",
      "---------------------------- Epoch 97 ----------------------------\n",
      "|       | batch  30 | correct total: 0.15927419 | loss total: 0.06602920 |\n",
      "|       | batch  60 | correct total: 0.14959016 | loss total: 0.06625762 |\n",
      "|       | batch  90 | correct total: 0.15041209 | loss total: 0.06627425 |\n",
      "|       | batch 120 | correct total: 0.14979339 | loss total: 0.06629019 |\n",
      "|       | batch 150 | correct total: 0.14279801 | loss total: 0.06635571 |\n",
      "|       | batch 180 | correct total: 0.14450967 | loss total: 0.06632071 |\n",
      "| test  | accuracy: 0.1263 | loss avg: 0.06724866 | 5017.60 sec |\n",
      "---------------------------- Epoch 98 ----------------------------\n",
      "|       | batch  30 | correct total: 0.13407258 | loss total: 0.06642831 |\n",
      "|       | batch  60 | correct total: 0.13627049 | loss total: 0.06624886 |\n",
      "|       | batch  90 | correct total: 0.14079670 | loss total: 0.06631571 |\n",
      "|       | batch 120 | correct total: 0.13868802 | loss total: 0.06635802 |\n",
      "|       | batch 150 | correct total: 0.13886589 | loss total: 0.06630694 |\n",
      "|       | batch 180 | correct total: 0.14243785 | loss total: 0.06629972 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test  | accuracy: 0.1392 | loss avg: 0.06714992 | 5068.11 sec |\n",
      "---------------------------- Epoch 99 ----------------------------\n",
      "|       | batch  30 | correct total: 0.16633065 | loss total: 0.06617903 |\n",
      "|       | batch  60 | correct total: 0.15881148 | loss total: 0.06628424 |\n",
      "|       | batch  90 | correct total: 0.15556319 | loss total: 0.06632357 |\n",
      "|       | batch 120 | correct total: 0.15573347 | loss total: 0.06635371 |\n",
      "|       | batch 150 | correct total: 0.15086921 | loss total: 0.06631406 |\n",
      "|       | batch 180 | correct total: 0.15124309 | loss total: 0.06630367 |\n",
      "| test  | accuracy: 0.1405 | loss avg: 0.06837358 | 5119.10 sec |\n",
      "done!\n",
      "/tmp/work/livedoor/model/emb=random&edim=300&model=lstm&hdim=100&batchsize=032&optim=sgd&lr=0.10000&mo=0.9&epochs= 100&shuffle=True.pth : created\n",
      "/tmp/work/livedoor/log/emb=random&edim=300&model=lstm&hdim=100&batchsize=032&optim=sgd&lr=0.10000&mo=0.9&epochs= 100&shuffle=True.csv : created\n"
     ]
    }
   ],
   "source": [
    "# model setting\n",
    "model_name = 'lstm'\n",
    "embed_type = 'random'\n",
    "embed_dim = 300\n",
    "hidden_dim = 100\n",
    "\n",
    "# training setting\n",
    "batchsizes = [32]\n",
    "lrs = [1e-1]\n",
    "mos = [0.9]\n",
    "n_epochss = [100]\n",
    "\n",
    "# for (batchsize, lr, mo, n_epochs) in itertools.product(batchsizes, lrs, mos, n_epochss):\n",
    "# dataloader\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=batchsize,\n",
    "                              shuffle=True,)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                              batch_size=batchsize,\n",
    "                              shuffle=True,)\n",
    "\n",
    "# define network architecture\n",
    "model = LSTMClassifier(len(vocab), embed_dim, hidden_dim, 9).to(DEVICE)\n",
    "\n",
    "# modules\n",
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=mo)\n",
    "\n",
    "# train model\n",
    "result = []\n",
    "start = time()\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    print(f'{\"-\"*28} Epoch {epoch} {\"-\"*28}')\n",
    "    train_acc, train_loss = iter_train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_acc, test_loss = iter_test(test_dataloader, model, loss_fn)\n",
    "    print(f' {time()-start:5.2f} sec |')\n",
    "    result.append((epoch, train_acc, train_loss, test_acc, test_loss))\n",
    "\n",
    "print('done!')\n",
    "\n",
    "# **\n",
    "# save\n",
    "# *\n",
    "filename_base = f'emb={embed_type}&edim={embed_dim:03d}' \\\n",
    "                f'&model={model_name}&hdim={hidden_dim:03d}' \\\n",
    "                f'&batchsize={batchsize:03d}' \\\n",
    "                f'&optim=sgd&lr={lr:.5f}&mo={mo:.1f}' \\\n",
    "                f'&epochs={n_epochs:4d}' \\\n",
    "                f'&shuffle=True'\n",
    "filename_model = os.path.join(DIR_MODEL, filename_base+'.pth')\n",
    "filename_log = os.path.join(DIR_LOG, filename_base+'.csv')\n",
    "\n",
    "# save model\n",
    "if not os.path.isfile(filename_model):\n",
    "    torch.save(model, filename_model)\n",
    "    print(f'{filename_model} : created')\n",
    "else:\n",
    "    print(f'{filename_model} : exists')\n",
    "\n",
    "# save log\n",
    "if not os.path.isfile(filename_log):\n",
    "    result = pd.DataFrame(result).rename(columns={0: 'epoch',\n",
    "                                                  1: 'train_acc',\n",
    "                                                  2: 'train_loss',\n",
    "                                                  3: 'test_acc',\n",
    "                                                  4: 'test_loss'})\n",
    "    result.to_csv(filename_log, index=False)\n",
    "    print(f'{filename_log} : created')\n",
    "else:\n",
    "    print(f'{filename_log} : exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ee00c",
   "metadata": {},
   "source": [
    "過学習、バッチ shuffle してなかったからでは？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea77ef",
   "metadata": {},
   "source": [
    "そもそもおかしいところ\n",
    "- 特定のラベルに推論結果が偏る\n",
    "- test なのに正答しない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3e9ed",
   "metadata": {},
   "source": [
    "なやみ\n",
    "- 過学習する\n",
    "- 収束しない\n",
    "- ９値分類で推定結果が１つだけに偏る；１epoch 目からそんな感じ．初期値がかたよってるから？（散らばらせることできる？）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ea349",
   "metadata": {},
   "source": [
    "- embedding の 重みって，分散表現とべつであるか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde176b",
   "metadata": {},
   "source": [
    "- model 生成の順序を修正したから改善した？Embedding.require_grad=False を無効にしたから改善した？（先に進む前に，一度確認すべき）\n",
    "- 32, 64 128 で 1e-0 で試してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becda21d",
   "metadata": {},
   "source": [
    "- train, test ともに，モデルの出力結果（Loss()に入れる直前の生の出力値）を受け取って評価するつくりに変更\n",
    "- → train, test をスタンドアロンに動かせるようになる．\n",
    "- → テストだけ実行して，未学習時点における推論結果の偏り有無を確認する（偏ってたら，パラメータ初期値が好ましくないという仮説の立証に一歩近づく）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba06fb0",
   "metadata": {},
   "source": [
    "embedding の weight 更新 True にして試行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8163c340",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bedbcab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mcrosstab\u001b[0;34m(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_colnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     }\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0moriginal_df_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         ]\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             val = sanitize_array(\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             )\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def predict_dataloader(dataloader, model):\n",
    "\n",
    "    y = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 全ての勾配計算を無効化\n",
    "        for batch, (labels, texts) in enumerate(dataloader):\n",
    "            \n",
    "            y.append(list(labels.numpy()))\n",
    "            \n",
    "            # indexing\n",
    "            texts = [torch.tensor(text_pipeline(text)) for text in texts]\n",
    "            texts = pad_sequence(texts, batch_first=True, padding_value=PAD)\n",
    "            \n",
    "            # send to GPU\n",
    "            labels, texts = labels.to(DEVICE), texts.to(DEVICE)\n",
    "            \n",
    "            # predict\n",
    "            if batch==0:\n",
    "                y_pred = model(texts)[0].cpu().numpy()\n",
    "            else:\n",
    "                y_pred = np.append(y_pred, model(texts)[0].cpu().numpy(), axis=0)\n",
    "    \n",
    "    return np.array(list(itertools.chain.from_iterable(y))), y_pred#.argmax(axis=1)\n",
    "\n",
    "f = 'emb=random&edim=300&model=lstm&hdim=100&batchsize=128&optim=sgd&lr=0.00003&mo=0.9&epochs=1.pth'\n",
    "model = torch.load(os.path.join(DIR_MODEL, f))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                              batch_size=128,\n",
    "                              shuffle=False,)\n",
    "y, y_pred = predict_dataloader(test_dataloader, model)\n",
    "sns.heatmap(pd.crosstab(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab96bda4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10310535, -0.05537033,  0.0144057 , ...,  0.02722622,\n",
       "         0.00404025,  0.07488791],\n",
       "       [ 0.10310535, -0.05537033,  0.01440569, ...,  0.02722622,\n",
       "         0.00404026,  0.07488791],\n",
       "       [ 0.10310535, -0.05537033,  0.0144057 , ...,  0.02722622,\n",
       "         0.00404026,  0.07488791],\n",
       "       ...,\n",
       "       [ 0.10310535, -0.05537033,  0.0144057 , ...,  0.02722622,\n",
       "         0.00404026,  0.07488791],\n",
       "       [ 0.10310535, -0.05537033,  0.0144057 , ...,  0.02722622,\n",
       "         0.00404026,  0.07488791],\n",
       "       [ 0.10310535, -0.05537033,  0.0144057 , ...,  0.02722622,\n",
       "         0.00404026,  0.07488791]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_with_word_embedding(model, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c856c8",
   "metadata": {},
   "source": [
    "# Primitive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb1324",
   "metadata": {},
   "source": [
    "create feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d404d6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5893, 300) (5893,)\n",
      "(1473, 300) (1473,)\n"
     ]
    }
   ],
   "source": [
    "def get_embedding_table(dataloader):\n",
    "    X, y = [], []\n",
    "    for batch, (labels, texts) in enumerate(dataloader):\n",
    "        texts = [torch.tensor(text_pipeline(text)) for text in texts]\n",
    "        texts = pad_sequence(texts, batch_first=True, padding_value=PAD)\n",
    "        labels, texts = labels.to(DEVICE), texts.to(DEVICE)\n",
    "        emb = model.embedding(texts).detach().cpu().numpy().mean(axis=1)\n",
    "        X.append(emb)\n",
    "        y.append(labels.detach().cpu().numpy())\n",
    "    \n",
    "    X = np.array(list(itertools.chain.from_iterable(X)))\n",
    "    y = np.array(list(itertools.chain.from_iterable(y)))\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "model = LSTMClassifier(len(vocab), 300, 100, 9).to(DEVICE)\n",
    "X_train, y_train = get_embedding_table(train_dataloader)\n",
    "X_test, y_test = get_embedding_table(test_dataloader)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b704fb0e",
   "metadata": {},
   "source": [
    "feature overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 300)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x311.04 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def show(embedding):\n",
    "    w = 18\n",
    "    h = embedding.shape[0] * (w / 300) * 8\n",
    "\n",
    "    fig = plt.figure(figsize=(w, h))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    print(embedding.shape)\n",
    "    sns.heatmap(pd.DataFrame(embedding), cbar=False, xticklabels=False, yticklabels=False, cmap='Blues')\n",
    "\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "df = pd.DataFrame(X_train)\n",
    "show(df.groupby(y_train).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb6d4e",
   "metadata": {},
   "source": [
    "ベンチマーク；SVM で 82 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38e83bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268839103869654"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "sum(y_pred == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "345b8459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "sns.heatmap(pd.crosstab(y_test, y_pred), cbar=False, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59c3a0",
   "metadata": {},
   "source": [
    "# Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# embed\n",
    "wv = KeyedVectors.load_word2vec_format('/data/chive/chive-1.2-mc5/chive-1.2-mc5.txt')\n",
    "wv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
