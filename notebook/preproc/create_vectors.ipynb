{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f0de66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEVICE': 'cpu',\n",
      " 'DIR_BIN': '/tmp/work/livedoor/bin',\n",
      " 'DIR_DATA': '/tmp/work/livedoor/data',\n",
      " 'DIR_LOG': '/tmp/work/livedoor/log',\n",
      " 'DIR_MECAB_DIC': '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd',\n",
      " 'DIR_MODEL': '/tmp/work/livedoor/model',\n",
      " 'ROOT': '/tmp/work/livedoor',\n",
      " 'SAMPLE_SENT': 'ワンマンライブに行きたい。',\n",
      " 'SEED': 123,\n",
      " 'TOKENIZER': 'mecab'}\n"
     ]
    }
   ],
   "source": [
    "# primitive\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# text\n",
    "import MeCab\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "# **\n",
    "# handmade libs\n",
    "# *\n",
    "src = '../../src'\n",
    "if src not in sys.path: sys.path.append(src)\n",
    "\n",
    "# constants\n",
    "from const import *\n",
    "constants = {k: v for k, v in locals().items() if k.isupper()}\n",
    "pprint(constants)\n",
    "\n",
    "# modules\n",
    "from my_tokenizer import get_tokenizer\n",
    "from livedoor_dataset import LivedoorDataset\n",
    "from sudachi_tokenizer import SudachiTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd3178",
   "metadata": {},
   "source": [
    "# Preprocess for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1840358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab\n",
    "ENGINE = 'sudachi'\n",
    "DICT = 'core'\n",
    "DATASET = 'livedoor'\n",
    "EMBEDDING = 'chive_mc90'\n",
    "VERSION = 'intersection'\n",
    "file_vocab = os.path.join(DIR_BIN, f'{ENGINE}.{DICT}.{DATASET}.{EMBEDDING}.{VERSION}.vocab.pkl')\n",
    "with open(file_vocab, 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "# 学習済み単語分散表現\n",
    "vectors = gensim.models.KeyedVectors.load('/data/chive_v1.2mc90/chive-1.2-mc90_gensim/chive-1.2-mc90.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab03bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors を作る\n",
    "def create_vectors(vocab, vectors):\n",
    "    '''学習・推論時に用いる単語分散表現のベクトル\n",
    "    Args:\n",
    "      vocab: 学習用コーパスの語彙と学習済単語ベクトルの語彙に共通で登場する語彙。torchtext.vocab.Vocab\n",
    "      pretrained_embedding: 上記 vocab 構築時に参照した単語分散表現\n",
    "    Returns:\n",
    "      語に対応するインデックスの要素として語に対応するベクトルを持つ numpy.array\n",
    "    '''\n",
    "    words = [vocab.itos[i] for i in range(len(vocab))]\n",
    "    emb_pretrained = np.array([vectors[w] for w in words[2:]])\n",
    "    emb_for_model = np.zeros((2, 300))\n",
    "    emb_for_model = np.concatenate((emb_for_model, emb_pretrained), axis=0)\n",
    "    \n",
    "    return emb_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3969746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 575 ms, sys: 173 ms, total: 748 ms\n",
      "Wall time: 2.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_embedding = os.path.join(DIR_BIN, f'{ENGINE}.{DICT}.{DATASET}.{EMBEDDING}.{VERSION}.embedding.pkl')\n",
    "if os.path.isfile(file_embedding):\n",
    "    print(f'file exists: {file_vocab}')\n",
    "    pass\n",
    "else:\n",
    "    emb_for_model = create_vectors(vocab, vectors)\n",
    "    with open(file_embedding, 'wb') as f:\n",
    "        pickle.dump(emb_for_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
